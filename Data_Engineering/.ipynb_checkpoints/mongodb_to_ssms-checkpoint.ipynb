{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5acd5b41-49cf-43c8-80fa-4c0746a6e29e",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a521d279-c28a-4078-ada3-d4abb47dc140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pyodbc\n",
    "import snowflake.connector\n",
    "import pyodbc\n",
    "import csv\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import snowflake as sf\n",
    "from snowflake import connector\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6ceba-7c77-4a6c-b5f4-50cae66fe874",
   "metadata": {},
   "source": [
    "### Mongodb Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fdabe-eb00-4e13-9e40-1e8b6273378b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a129647-168a-4242-9aa0-fc7910c1c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection settings\n",
    "mongo_uri = \"mongodb+srv://NandaKumar:Nandareddy%40123@cluster0.s9jwc.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "mongo_database = \"CustomerData\"\n",
    "# Add your collection names here\n",
    "mongo_collection1 = \"UserData\" \n",
    "\n",
    "mongo_collection2 = \"TimeSheetData\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dac64f-90d4-4dc8-a379-a05fe49db48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV output file\n",
    "CSV_FILE_USER_DATA = 'user_data.csv'\n",
    "CSV_FILE_TIMESHEET_DATA = 'timesheet_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29df332-ae90-468f-8e81-461773c9075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from collection UserData exported to user_data.csv\n",
      "Exported data from collection UserData to user_data.csv\n",
      "Data from collection TimeSheetData exported to timesheet_data.csv\n",
      "Exported data from collection TimeSheetData to timesheet_data.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def export_to_csv(collection_name, csv_file, mongo_uri, mongo_database):\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[mongo_database]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Retrieve data from MongoDB collection\n",
    "    cursor = collection.find()\n",
    "    documents = list(cursor)\n",
    "\n",
    "    # Write data to CSV file\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        fieldnames = set().union(*(document.keys() for document in documents))\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for document in documents:\n",
    "            writer.writerow(document)\n",
    "\n",
    "    print(\"Data from collection\", collection_name, \"exported to\", csv_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MongoDB connection settings\n",
    "    mongo_uri = \"mongodb+srv://NandaKumar:Nandareddy%40123@cluster0.s9jwc.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "    mongo_database = \"CustomerData\"\n",
    "    # Add your collection names here\n",
    "    mongo_collection1 = \"UserData\" \n",
    "    mongo_collection2 = \"TimeSheetData\"\n",
    "    # CSV output file\n",
    "    CSV_FILE_USER_DATA = 'user_data.csv'\n",
    "    CSV_FILE_TIMESHEET_DATA = 'timesheet_data.csv'\n",
    "    \n",
    "    export_to_csv(mongo_collection1, CSV_FILE_USER_DATA, mongo_uri, mongo_database)\n",
    "    print(\"Exported data from collection\", mongo_collection1, \"to\", CSV_FILE_USER_DATA)\n",
    "    \n",
    "    export_to_csv(mongo_collection2, CSV_FILE_TIMESHEET_DATA, mongo_uri, mongo_database)\n",
    "    print(\"Exported data from collection\", mongo_collection2, \"to\", CSV_FILE_TIMESHEET_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456664e7-c8ad-45e7-a0d3-45603997c7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9023315-bb8f-4694-b722-f51d7bc64a02",
   "metadata": {},
   "source": [
    "### Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b8b502-5b89-4393-ac28-65cea635fc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0b6b844-f539-48ae-9b34-8d8625d984dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "    snowflake_conn = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USER\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        warehouse=os.environ[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"],\n",
    "        schema=os.environ[\"SNOWFLAKE_SCHEMA\"],\n",
    "        role = os.environ[\"SNOWFLAKE_ROLE\"]\n",
    "    )\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20234ba4-d09c-4589-aa50-710f36391732",
   "metadata": {},
   "source": [
    "### Inserting Data into snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7304cf55-2d4d-477d-92ee-af4f54697d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'feedback.csv' inserted into 'feedback' table in Snowflake.\n",
      "Data from 'questions.csv' inserted into 'questions' table in Snowflake.\n",
      "Data from 'timesheet.csv' inserted into 'timesheet' table in Snowflake.\n",
      "Data from 'userdata.csv' inserted into 'userdata' table in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create staging_raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    print(\"No data to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each CSV file in the staging_raw_data folder\n",
    "for filename in os.listdir(\"staging_raw_data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract table name from filename (remove .csv extension)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"staging_raw_data/{filename}\")\n",
    "        \n",
    "        # Replace NaN values with empty strings\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Convert all data to string\n",
    "        df = df.astype(str)\n",
    "        \n",
    "        # Create table in Snowflake if it doesn't exist\n",
    "        snowflake_cursor = snowflake_conn.cursor()\n",
    "        create_table_query = f\"CREATE TABLE IF NOT EXISTS {table_name} (\"\n",
    "        for column in df.columns:\n",
    "            create_table_query += f\"{column} VARCHAR,\"\n",
    "        create_table_query = create_table_query[:-1] + \")\"  # Remove trailing comma\n",
    "        snowflake_cursor.execute(create_table_query)\n",
    "        \n",
    "        # Prepare INSERT INTO statement\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({','.join(['%s'] * len(df.columns))})\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (rows)\n",
    "        rows = [tuple(row) for row in df.itertuples(index=False)]\n",
    "        \n",
    "        # Execute bulk insert\n",
    "        snowflake_cursor.executemany(insert_query, rows)\n",
    "        snowflake_cursor.close()\n",
    "        \n",
    "        print(f\"Data from '{filename}' inserted into '{table_name}' table in Snowflake.\")\n",
    "\n",
    "# Commit the transaction\n",
    "snowflake_conn.commit()\n",
    "\n",
    "# Close Snowflake connection\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958eca58-f459-4a17-bcbc-fc2ea3ef9654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
